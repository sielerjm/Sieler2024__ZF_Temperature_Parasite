---
title: "DADA2 Pipeline"
author: "Michael Sieler"
date: "2023-12-21"
output: html_document
---

# Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
root.dir = rprojroot::find_rstudio_root_file()

# LIBRARIES

## MICROBIOME
library(dada2)
library(phyloseq)
library(phyloseqCompanion)
library(microViz)


## MISÃ‡ (load last to avoid conflicts)
library(tidyverse)


# SET PATHS
proj.path <- root.dir

path.code <- paste0(proj.path,"/Code")
# Create dir if it doesn't exist
if (!dir.exists(path.code)) { dir.create(path.code) } 

path.data <- paste0(proj.path,"/Data")
if (!dir.exists(path.data)) { dir.create(path.data) }

path.input <- file.path(path.data,"Input") 
if (!dir.exists(path.input)) { dir.create(path.input) }

path.output <- file.path(path.data, "Output")
if (!dir.exists(path.output)) { dir.create(path.output) }

## Path to Robjects (Renv, Rds, Rdata, etc.) saved here
path.objects <- paste0(path.data,  # Project path
                                  "/R_objects")  # Sub-directory
if (!dir.exists(path.objects)) { dir.create(path.objects) }

## Path to Output (Figures, Tables)
output.path <- paste0(path.output, "/",
                      "dada2_", packageVersion("dada2"),  # Dada2 Version
                      "_", Sys.Date()  # Date
                      )
if (!dir.exists(output.path)) { dir.create(output.path) }

path.rawFastq <- file.path(path.data, "Raw", "Sequences_Raw")

# inDir <- path.input


# Setting Variables for DADA2 Pipeline

# Local

# Taxonomy
taxa.db.path <- "/Users/michaelsieler/Dropbox/Mac (2)/Documents/Sharpton_Lab/Bioinformatics_files/silva_nr99_v138.1_train_set.fa" # path to database to be used for assigning taxonomy. Should be a gzipped FASTA file.
fasttree.path = "/Users/michaelsieler/Dropbox/Mac (2)/Documents/Sharpton_Lab/Bioinformatics_files/Symlinks/FastTree"

# Server

# ## Taxonomy
# taxa.db.path <- "/nfs3/Sharpton_Lab/public_databases/silva_nr_v138_train_set.fa.gz" # path to database to be used for assigning taxonomy. Should be a gzipped FASTA file.
# # 16S database can be found here:
# #  https://benjjneb.github.io/dada2/training.html
# 
# ## FastTree
# fasttree.path <- "/local/cluster/bin/FastTreeMP" #"/nfs3/Sharpton_Lab/tmp/src/stagamak/FastTreeMP" # path to the FastTree executable
# 
# ## Cores for parallel processing
# maxCores = 10 # Anything 10 or under is okay, but if you need more on Rstudio Cloud server check with someone first (e.g., Ed Davis)

```


# Load Data

Check that files exist where we expect them to be. We should see files ending in `.fastq` or `.fastq.gz`.

```{r}
list.files(path.rawFastq) %>% 
  head(10) # Show first 10 files
```

## Read in seqs

```{r}

# Forward Reads (`_R1_`)
fnFs <- sort(list.files(path.rawFastq, pattern="_R1_001.fastq", full.names = TRUE))

# Reverse Reads (`_R2_`)
fnRs <- sort(list.files(path.rawFastq, pattern="_R2_001.fastq", full.names = TRUE))

# Should not return any message if files match. Okay to proceed
if(length(fnFs) != length(fnRs)) stop("Forward and reverse files do not match.")

# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- basename(fnFs) %>%  # Pulls the base file name
  str_extract("-[A-Z]+\\d+") %>%  # Extracts sample name
  str_remove("-")  # Removes extra characters we don't need



```


## Inspect read quality

```{r}

plotQualityProfile(fnFs[1:2])
plotQualityProfile(fnRs[1:2])

```

# Process Reads

## Filter and Trim

```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path.rawFastq, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path.rawFastq, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))


names(filtFs) <- sample.names
names(filtRs) <- sample.names

```


```{r}
  Sys.time()
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,200),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
  Sys.time()
head(out)

```

## Learn Error Rates

```{r}
  Sys.time()
errF <- learnErrors(filtFs, multithread=TRUE)
  Sys.time()
errR <- learnErrors(filtRs, multithread=TRUE)
  Sys.time()
```


### Plot
```{r}
plotErrors(errF, nominalQ=TRUE)
plotErrors(errR, nominalQ=TRUE)
```

## Sample Inference

```{r}

# Troubleshooting

## Check for duplicate file names. Should all be FALSE
any(duplicated(sample.names)) 
any(duplicated(c(fnFs, fnRs)))
any(duplicated(c(filtFs, filtRs)))

## Check which sequences didn't pass filter
fnFs[!file.exists(filtFs)] 
fnRs[!file.exists(filtRs)]

# Re-assign existing filenames
##    If some sequences do not pass the filter and trim step, they will be dropped and your list of sequences found in fnFs & filtFs (fnRs & filtRs) will not match. To reconcile that, we do the following:
filtFs <- filtFs[file.exists(filtFs)] 
filtRs <- filtRs[file.exists(filtRs)] 
```



```{r}

# Forward
  Sys.time()
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
  Sys.time()

# Reverse
  Sys.time()
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)
  Sys.time()

# Inspect the returned dada-class object
dadaFs[[1]]
dadaRs[[1]]
```

# Post-Process

## Merge Paired Reads

```{r}
  Sys.time()
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
  Sys.time()
# Inspect the merger data.frame from the first sample
head(mergers[[1]])

```


## Construct a sequence table

```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)

# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```

## Remove chimeras

```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
sum(seqtab.nochim)/sum(seqtab)
```

## Track reads through the pipeline

```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```

## Assign taxonomy

```{r}
taxa <- assignTaxonomy(seqtab.nochim, taxa.db.path, multithread=TRUE)

# Inspect taxonomy
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
```

# Phyloseq

## Metadata

### Import metadata

```{r}
# Import CSV file
metadata <- read_csv(file.path(path.data,"Clean/Metadata/metadata.csv")) 

# Add a column to be used for rownames
metadata <-
  metadata %>%
    mutate(rowname.col = Sample) %>%
  filter(!str_detect(Sample, "Utah")) %>%
  
  # Fix row contents
  mutate(
    Experiment = as.integer(str_remove(Experiment," dpe")),
    Tank.ID = as.integer(str_remove(Tank.ID,"IS"))
  ) %>%
  
  # Fix column names
  rename(
    Age = "Age.Days",
    Timepoint = "Experiment",
    TankID = "Tank.ID",
    Weight = "Weight_mg",
    Worm.Count = "Total.Worm.Count"
  )

tmp.samp <- sample_data(metadata %>% column_to_rownames("rowname.col"))
```

### OTU Table

```{r}

tmp.OTU <- otu_table(seqtab.nochim, taxa_are_rows=FALSE)

```


### TAX Table

```{r}

tmp.TAX <- tax_table(taxa)

```


## Construct Phyloseq Object

```{r}
ps0 <- phyloseq(tmp.OTU, 
               tmp.samp, 
               tmp.TAX)

# Check that phyloseq object was created as expected
ps0
```

## Phylogenetic Tree

```{r}

# Set variables (adapted from Keaton's DADA2 pipeline)
build.tree = TRUE
guide.seqs.file = NULL
alignment.template.file = NULL
user.output.path = output.path
paired = T
force = FALSE

ps1 <- phyloseqCompanion::numbered.ASVs(
        ps = ps0,
        # prefix = paste0(proj.name, "_ASV"),
        save.dir = output.path,
        save.file = "asv_sequences"
      )
asv.seqs <- readRDS(file.path(user.output.path, "asv_sequences.rds"))

####

# seqinR can't be installed, because it depends on Segmented package which fails to install due to system issues
seqinr::write.fasta(
      sequences = as.list(asv.seqs),
      names = taxa_names(ps1),
      as.string = TRUE,
      file.out = file.path(user.output.path, "asv_sequences.fasta")
    )

# ## Alternative Code
# dna_seqs <- Biostrings::DNAStringSet(asv.seqs, names = taxa_names(ps0))
# 
# # Write to a FASTA file
# output_path <- file.path(output, "asv_sequences.fasta")
# Biostrings::writeXStringSet(dna_seqs, filepath = output_path)

####

if (is.null(user.output.path)) {
  output <- run.env$output.path
} else {
  output <- user.output.path
}
# if (!any(file.exists(list.files(path = output, pattern = "qualPlot.pdf", full.names = T)))) {
#   stop("Function 'dada2.upto.qualPlots()' must be run first.")
# }
if (build.tree) {
  if (length(suppressWarnings(system("which mothur", intern = T))) == 0) {
    stop(
      "It appears you are trying to build a phylogenetic tree, but mothur is not installed on your system. Please install mothur and try again."
    )
  }
  if (is.null(fasttree.path) | !file.exists(fasttree.path)) {
    stop(
      "It appears you are trying to build a phylogenetic tree, but you have not provided a viable path to FastTree."
    )
  }
  if (is.null(guide.seqs.file)) {
    writeLines(guide.seqs.lines, con = "guide_seqs.fasta")
    guide.seqs.file <- "guide_seqs.fasta"
  }
  if (is.null(alignment.template.file)) {
    writeLines(alignment.template.file.lines, con = "template.align")
    alignment.template.file <- "template.align"
  }
  if (!(
    guide.seqs.file %in% list.files() &
    alignment.template.file %in% list.files()
  )) {
    stop(
      paste(
        "Files", guide.seqs.file, "and", alignment.template.file,
        "must be in your current directory to build a tree."
      )
    )
  }
}

 my.cat("Proceeding with phylogenetic tree:")
  asv.seqs.file <- file.path(output, "asv_sequences.fasta")
  asv.withguides.file  <- file.path(output, "asv_and_guide_seqs.fasta")
  asv.tree.rooted.file <- file.path(output, "asv_NASTaligned_seqs.nwk")
  
  cmd <- paste0(
    "cat '",
    asv.seqs.file, "' '",
    guide.seqs.file,
    "' > '",
    asv.withguides.file,"'"
  )
  system(cmd)
  
  my.cat("Aligning sequences...")
  cmd <- paste0(
    "mothur \"#align.seqs( fasta=",
    asv.withguides.file,
    ", reference=",
    alignment.template.file,
    ", flip=t",
    ", keepdots=t",
    ", processors=", maxCores = maxCores,
    ", outputdir=",
    output,
    "/ )\""
  )
  system(cmd)
  my.cat("\tDONE")
  
  mothur.output.file <- file.path(output, "asv_and_guide_seqs.align")
  fasttree.log.file <- file.path(output, "fasttree.log")
  fasttree.output.file <- file.path(output, "asv_and_guide_seqs.nwk")
  
  my.cat("Building phylogenetic tree...")
  cmd <- paste0(
    "export OMP_NUM_THREADS=",
    maxCores = maxCores, "; '",
    fasttree.path, "' -nt -nosupport -quote -gtr -gamma -log '",
    fasttree.log.file,
    "' '",
    mothur.output.file,
    "' > '",
    fasttree.output.file,
    "'"
  )
  system(cmd)
  my.cat("\tDONE")
  asvs.and.guides.tree <- read_tree(fasttree.output.file)
  asvs.and.guides.tree.rooted <- phangorn::midpoint(asvs.and.guides.tree)
  
  guides <- scan(guide.seqs.file, what = "character" )
  guide.ids <- guides[stringr::str_detect(guides, ">" )]
  guide.ids <- stringr::str_remove(guide.ids, ">")
  
  asvs.tree.rooted <- ape::drop.tip(asvs.and.guides.tree.rooted, guide.ids)
  write.tree(asvs.tree.rooted, file = asv.tree.rooted.file)
  
  phy_tree(ps1) <- phy_tree(asvs.tree.rooted)
  system(paste0("mv mothur* '", output,"'"))


```



# Clean phyloseq object

## Fix Taxa

```{r}

tmp.ps1 <-
ps1 %>% 
  tax_name(
    prefix = "ASV",
    rank = NA,
    pad_number = TRUE,
    sep = "_"
  )

# tmp.ps0@tax_table %>% view()

```


```{r message=FALSE, warning=FALSE}

tmp.ps2 <-
  tmp.ps1 %>%
    tax_fix(
      min_length = 4,
      unknowns = c(""),
      sep = " ", anon_unique = TRUE,
      suffix_rank = "classified"
     )

# tmp.ps1@tax_table %>% view()

```

### Plots

Let's see what our phyloseq object looks like

```{r}
tmp.ps2 %>%
  comp_barplot("Family", n_taxa = 10, merge_other = FALSE, label = NULL) +
  facet_wrap(Treatment ~ Timepoint, scales = "free") + # scales = "free" is IMPORTANT!
  coord_flip() 
```








